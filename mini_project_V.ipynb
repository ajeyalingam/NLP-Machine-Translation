{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "iSYG7xGEIoYc"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Embedding, RepeatVector, TimeDistributed\n",
    "from unicodedata import normalize\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from numpy import array\n",
    "import pickle\n",
    "#from keras.utils.vis_utils import plot_model\n",
    "\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Eme9JU8GIoYk"
   },
   "source": [
    "## Language Translator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Zv56gAJqIoYk"
   },
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w4ACzJxRIoYl"
   },
   "source": [
    "From `nltk` we can download translated sentences between different languages. You can see the example between **English and French** below but feel free to try different combination as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4sSNypocIoYl",
    "outputId": "81278f78-846c-4cf6-9ed3-dd902e48098c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package comtrans to /home/aj/nltk_data...\n",
      "[nltk_data]   Package comtrans is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('comtrans')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 986
    },
    "id": "0bqFzuH0IoYm",
    "outputId": "aecb46d9-1aa8-43d6-8855-7b9b0891db2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<AlignedSent: 'Resumption of the se...' -> 'Reprise de la sessio...'>\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import comtrans\n",
    "print(comtrans.aligned_sents('alignment-en-fr.txt')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "c7XNVz11IoYn",
    "outputId": "981347e8-8cb6-4bd6-ab26-588133518907"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33334"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(comtrans.aligned_sents('alignment-en-fr.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "7qhOFOTjIoYn",
    "outputId": "624211fc-c525-4671-e346-1c5d2a198194"
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.43.0 (0)\n",
       " -->\n",
       "<!-- Title: align Pages: 1 -->\n",
       "<svg width=\"885pt\" height=\"140pt\"\n",
       " viewBox=\"0.00 0.00 885.00 139.96\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 135.96)\">\n",
       "<title>align</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-135.96 881,-135.96 881,4 -4,4\"/>\n",
       "<!-- Please_source -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>Please_source</title>\n",
       "<text text-anchor=\"middle\" x=\"99\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">Please</text>\n",
       "</g>\n",
       "<!-- rise_source -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>rise_source</title>\n",
       "<text text-anchor=\"middle\" x=\"176\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">rise</text>\n",
       "</g>\n",
       "<!-- Please_source&#45;&#45;rise_source -->\n",
       "<!-- Je_target -->\n",
       "<g id=\"node12\" class=\"node\">\n",
       "<title>Je_target</title>\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">Je</text>\n",
       "</g>\n",
       "<!-- Please_source&#45;&#45;Je_target -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>Please_source&#45;&#45;Je_target</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M81.2,-71.7C70.04,-60.85 55.71,-46.92 44.59,-36.1\"/>\n",
       "</g>\n",
       "<!-- vous_target -->\n",
       "<g id=\"node13\" class=\"node\">\n",
       "<title>vous_target</title>\n",
       "<text text-anchor=\"middle\" x=\"99\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">vous</text>\n",
       "</g>\n",
       "<!-- Please_source&#45;&#45;vous_target -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>Please_source&#45;&#45;vous_target</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M93.08,-71.7C91.97,-60.85 91.97,-46.92 93.1,-36.1\"/>\n",
       "</g>\n",
       "<!-- Please_source&#45;&#45;vous_target -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>Please_source&#45;&#45;vous_target</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M104.92,-71.7C106.03,-60.85 106.03,-46.92 104.9,-36.1\"/>\n",
       "</g>\n",
       "<!-- invite_target -->\n",
       "<g id=\"node14\" class=\"node\">\n",
       "<title>invite_target</title>\n",
       "<text text-anchor=\"middle\" x=\"173\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">invite</text>\n",
       "</g>\n",
       "<!-- Please_source&#45;&#45;invite_target -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>Please_source&#45;&#45;invite_target</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M117.29,-71.7C128.76,-60.85 143.49,-46.92 154.92,-36.1\"/>\n",
       "</g>\n",
       "<!-- ,_source -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>,_source</title>\n",
       "<text text-anchor=\"middle\" x=\"248\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">,</text>\n",
       "</g>\n",
       "<!-- rise_source&#45;&#45;,_source -->\n",
       "<!-- lever_target -->\n",
       "<g id=\"node16\" class=\"node\">\n",
       "<title>lever_target</title>\n",
       "<text text-anchor=\"middle\" x=\"319\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">lever</text>\n",
       "</g>\n",
       "<!-- rise_source&#45;&#45;lever_target -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>rise_source&#45;&#45;lever_target</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M203.23,-75.67C228.68,-63.21 266.46,-44.72 291.87,-32.28\"/>\n",
       "</g>\n",
       "<!-- then_source -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>then_source</title>\n",
       "<text text-anchor=\"middle\" x=\"320\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">then</text>\n",
       "</g>\n",
       "<!-- ,_source&#45;&#45;then_source -->\n",
       "<!-- for_source -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>for_source</title>\n",
       "<text text-anchor=\"middle\" x=\"392\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">for</text>\n",
       "</g>\n",
       "<!-- ,_source&#45;&#45;for_source -->\n",
       "<!-- then_source&#45;&#45;,_source -->\n",
       "<!-- this_source -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>this_source</title>\n",
       "<text text-anchor=\"middle\" x=\"464\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">this</text>\n",
       "</g>\n",
       "<!-- for_source&#45;&#45;this_source -->\n",
       "<!-- pour_target -->\n",
       "<g id=\"node17\" class=\"node\">\n",
       "<title>pour_target</title>\n",
       "<text text-anchor=\"middle\" x=\"392\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">pour</text>\n",
       "</g>\n",
       "<!-- for_source&#45;&#45;pour_target -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>for_source&#45;&#45;pour_target</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M392,-71.7C392,-60.85 392,-46.92 392,-36.1\"/>\n",
       "</g>\n",
       "<!-- minute_source -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>minute_source</title>\n",
       "<text text-anchor=\"middle\" x=\"543\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">minute</text>\n",
       "</g>\n",
       "<!-- this_source&#45;&#45;minute_source -->\n",
       "<!-- cette_target -->\n",
       "<g id=\"node18\" class=\"node\">\n",
       "<title>cette_target</title>\n",
       "<text text-anchor=\"middle\" x=\"464\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">cette</text>\n",
       "</g>\n",
       "<!-- this_source&#45;&#45;cette_target -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>this_source&#45;&#45;cette_target</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M464,-71.7C464,-60.85 464,-46.92 464,-36.1\"/>\n",
       "</g>\n",
       "<!-- &#39;_source -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>&#39;_source</title>\n",
       "<text text-anchor=\"middle\" x=\"622\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">&#39;</text>\n",
       "</g>\n",
       "<!-- minute_source&#45;&#45;&#39;_source -->\n",
       "<!-- minute_target -->\n",
       "<g id=\"node19\" class=\"node\">\n",
       "<title>minute_target</title>\n",
       "<text text-anchor=\"middle\" x=\"543\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">minute</text>\n",
       "</g>\n",
       "<!-- minute_source&#45;&#45;minute_target -->\n",
       "<g id=\"edge13\" class=\"edge\">\n",
       "<title>minute_source&#45;&#45;minute_target</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M543,-71.7C543,-60.85 543,-46.92 543,-36.1\"/>\n",
       "</g>\n",
       "<!-- s_source -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>s_source</title>\n",
       "<text text-anchor=\"middle\" x=\"694\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">s</text>\n",
       "</g>\n",
       "<!-- &#39;_source&#45;&#45;s_source -->\n",
       "<!-- silence_target -->\n",
       "<g id=\"node21\" class=\"node\">\n",
       "<title>silence_target</title>\n",
       "<text text-anchor=\"middle\" x=\"736\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">silence</text>\n",
       "</g>\n",
       "<!-- &#39;_source&#45;&#45;silence_target -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>&#39;_source&#45;&#45;silence_target</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M649.02,-72.41C666.79,-61.49 690.01,-47.24 707.99,-36.2\"/>\n",
       "</g>\n",
       "<!-- silence_source -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>silence_source</title>\n",
       "<text text-anchor=\"middle\" x=\"772\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">silence</text>\n",
       "</g>\n",
       "<!-- s_source&#45;&#45;silence_source -->\n",
       "<!-- de_target -->\n",
       "<g id=\"node20\" class=\"node\">\n",
       "<title>de_target</title>\n",
       "<text text-anchor=\"middle\" x=\"658\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">de</text>\n",
       "</g>\n",
       "<!-- s_source&#45;&#45;de_target -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>s_source&#45;&#45;de_target</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M685.1,-71.7C679.52,-60.85 672.36,-46.92 666.8,-36.1\"/>\n",
       "</g>\n",
       "<!-- s_source&#45;&#45;silence_target -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>s_source&#45;&#45;silence_target</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M704.38,-71.7C710.89,-60.85 719.25,-46.92 725.74,-36.1\"/>\n",
       "</g>\n",
       "<!-- ._source -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>._source</title>\n",
       "<text text-anchor=\"middle\" x=\"850\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">.</text>\n",
       "</g>\n",
       "<!-- silence_source&#45;&#45;._source -->\n",
       "<!-- silence_source&#45;&#45;silence_target -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>silence_source&#45;&#45;silence_target</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M763.1,-71.7C757.52,-60.85 750.36,-46.92 744.8,-36.1\"/>\n",
       "</g>\n",
       "<!-- ._target -->\n",
       "<g id=\"node22\" class=\"node\">\n",
       "<title>._target</title>\n",
       "<text text-anchor=\"middle\" x=\"832\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">.</text>\n",
       "</g>\n",
       "<!-- ._source&#45;&#45;._target -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>._source&#45;&#45;._target</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M845.55,-71.7C842.76,-60.85 839.18,-46.92 836.4,-36.1\"/>\n",
       "</g>\n",
       "<!-- Je_target&#45;&#45;vous_target -->\n",
       "<!-- vous_target&#45;&#45;invite_target -->\n",
       "<!-- vous_target&#45;&#45;lever_target -->\n",
       "<!-- à_target -->\n",
       "<g id=\"node15\" class=\"node\">\n",
       "<title>à_target</title>\n",
       "<text text-anchor=\"middle\" x=\"247\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">à</text>\n",
       "</g>\n",
       "<!-- invite_target&#45;&#45;à_target -->\n",
       "<!-- à_target&#45;&#45;vous_target -->\n",
       "<!-- lever_target&#45;&#45;pour_target -->\n",
       "<!-- pour_target&#45;&#45;cette_target -->\n",
       "<!-- cette_target&#45;&#45;minute_target -->\n",
       "<!-- minute_target&#45;&#45;de_target -->\n",
       "<!-- de_target&#45;&#45;silence_target -->\n",
       "<!-- silence_target&#45;&#45;._target -->\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "AlignedSent(['Please', 'rise', ',', 'then', ',', 'for', 'this', 'minute', ''', 's', 'silence', '.'], ['Je', 'vous', 'invite', 'à', 'vous', 'lever', 'pour', 'cette', 'minute', 'de', 'silence', '.'], Alignment([(0, 0), (0, 1), (0, 2), (0, 4), (1, 5), (5, 6), (6, 7), (7, 8), (8, 10), (9, 9), (9, 10), (10, 10), (11, 11)]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comtrans.aligned_sents('alignment-en-fr.txt')[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9Be7WX_PIoYo",
    "outputId": "d1b34489-dc4d-4e03-e10d-886a5424aa28"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['You', 'have', 'requested', 'a', 'debate', 'on', 'this', 'subject', 'in', 'the', 'course', 'of', 'the', 'next', 'few', 'days', ',', 'during', 'this', 'part-session', '.']\n",
      "['Vous', 'avez', 'souhaité', 'un', 'débat', 'à', 'ce', 'sujet', 'dans', 'les', 'prochains', 'jours', ',', 'au', 'cours', 'de', 'cette', 'période', 'de', 'session', '.']\n",
      "0-0 0-1 1-1 2-2 3-3 4-4 5-5 6-6 7-7 8-8 9-9 10-10 13-10 14-10 15-11 16-12 17-13 17-14 18-16 19-17 19-18 19-19 20-20\n"
     ]
    }
   ],
   "source": [
    "print(comtrans.aligned_sents('alignment-en-fr.txt')[2].words)\n",
    "print(comtrans.aligned_sents('alignment-en-fr.txt')[2].mots)\n",
    "print(comtrans.aligned_sents('alignment-en-fr.txt')[2].alignment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6Pv4fpQ1IoYo"
   },
   "outputs": [],
   "source": [
    "dataset = comtrans.aligned_sents('alignment-en-fr.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pf6Dm3bJIoYp"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "8NlRCaPFIoYq"
   },
   "outputs": [],
   "source": [
    "def retrieve_corpora(corpora):\n",
    "    print(\"Retrieving corpora: {}\".format(corpora))\n",
    "    als = comtrans.aligned_sents(corpora)\n",
    "    eng_sen = [sent.words for sent in als]\n",
    "    fre_sen = [sent.mots for sent in als]\n",
    "    return [eng_sen, fre_sen]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zsyz1jn4IoYr",
    "outputId": "aada6ae9-c13f-417a-9292-5d77993283ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving corpora: alignment-en-fr.txt\n"
     ]
    }
   ],
   "source": [
    "dataset = retrieve_corpora('alignment-en-fr.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "73zO2f1QIoYp"
   },
   "outputs": [],
   "source": [
    "pickle.dump(dataset, open('dataset.txt', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "fm_jvnIpLGPe"
   },
   "outputs": [],
   "source": [
    "dataset = pickle.load(open('dataset.txt', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "Hp6NmD7ZLfwj"
   },
   "outputs": [],
   "source": [
    "text1 = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "Vln39RI1Lf7u"
   },
   "outputs": [],
   "source": [
    "text2 = dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XrrNDZ0zIoYr",
    "outputId": "ff4bbe4d-f8e4-40f4-d1f8-3d97845f28e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English: ['Resumption', 'of', 'the', 'session']\n",
      "French: ['Reprise', 'de', 'la', 'session']\n",
      "# Corpora length (i.e. number of sentences)\n",
      "33334\n"
     ]
    }
   ],
   "source": [
    "print(\"English:\", text1[0])\n",
    "print(\"French:\", text2[0])\n",
    "print(\"# Corpora length (i.e. number of sentences)\")\n",
    "print(len(text2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "HGJP06JrIoYr"
   },
   "outputs": [],
   "source": [
    "def clean_sentence(sentence):\n",
    "    regex_splitter = re.compile('[^%s]' % re.escape(string.printable))\n",
    "    clean_words = [re.split(regex_splitter, word.lower()) for word in sentence]\n",
    "    return [w for words in clean_words for w in words if words if w]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WPGfOz1qIoYs",
    "outputId": "8289e4e4-057c-4c82-c1a4-bd7a25d0acc7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English: ['resumption', 'of', 'the', 'session']\n",
      "French: ['reprise', 'de', 'la', 'session']\n"
     ]
    }
   ],
   "source": [
    "clean_text1 = [clean_sentence(s) for s in text1]\n",
    "clean_text2 = [clean_sentence(s) for s in text2]\n",
    "print(\"English:\", clean_text1[0])\n",
    "print(\"French:\", clean_text2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "sRFE5KF0IoYs"
   },
   "outputs": [],
   "source": [
    "def filter_text(text1, text2, min_len=0, max_len=20):\n",
    "    filtered1 = []\n",
    "    filtered2 = []\n",
    "    for i in range(len(text1)):\n",
    "        if min_len <= len(text1[i]) <= max_len and min_len <= len(text2[i]) <= max_len:\n",
    "            filtered1.append(text1[i])\n",
    "            filtered2.append(text2[i])\n",
    "    return filtered1, filtered2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mS2wSEuDIoYt",
    "outputId": "f22af18f-8b06-4dce-a6d3-24ba646e71d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Filtered Corpora length (i.e. number of sentences)\n",
      "12861\n"
     ]
    }
   ],
   "source": [
    "filter_text1, filter_text2 = filter_text(clean_text1, clean_text2)\n",
    "print(\"# Filtered Corpora length (i.e. number of sentences)\")\n",
    "print(len(filter_text1))\n",
    "assert len(filter_text1) == len(filter_text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RIb4O1_rIoYu"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m1fYAFDhE3DX"
   },
   "source": [
    "Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "qE2uhthlKLwr"
   },
   "outputs": [],
   "source": [
    "# max sentence length\n",
    "def max_length(lines):\n",
    "    return max(len(line) for line in lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3v98h30wJ_jp",
    "outputId": "a6df7506-d906-4e09-fe77-bdc77234bf6f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 142,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length(filter_text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "MSvNhxrjIoYu"
   },
   "outputs": [],
   "source": [
    "def create_tokenizer(lines):\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(lines)\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bmr85SRLIoYu",
    "outputId": "978a63b7-cf76-44ef-df49-7f5de669bf57"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English Vocabulary Size: 8783\n",
      "English Max Length: 20\n",
      "French Vocabulary Size: 10264\n",
      "French Max Length: 20\n"
     ]
    }
   ],
   "source": [
    "# prepare english tokenizer\n",
    "eng_tokenizer = create_tokenizer(filter_text1)\n",
    "eng_vocab_size = len(eng_tokenizer.word_index) + 1\n",
    "eng_length = max_length(filter_text1)\n",
    "print('English Vocabulary Size: %d' % eng_vocab_size)\n",
    "print('English Max Length: %d' % (eng_length))\n",
    "\n",
    "# prepare french tokenizer\n",
    "fre_tokenizer = create_tokenizer(filter_text2)\n",
    "fre_vocab_size = len(fre_tokenizer.word_index) + 1\n",
    "fre_length = max_length(filter_text2)\n",
    "print('French Vocabulary Size: %d' % fre_vocab_size)\n",
    "print('French Max Length: %d' % (fre_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "id": "ZLi5ozDUIoYv"
   },
   "outputs": [],
   "source": [
    "def encode_sequences(tokenizer, length, lines):\n",
    "    # integer encode sequences\n",
    "    X = tokenizer.texts_to_sequences(lines)\n",
    "    # pad sequences with 0 values\n",
    "    X = pad_sequences(X, maxlen=length, padding='post')\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "kuSMo2mkIoYv"
   },
   "outputs": [],
   "source": [
    "# one hot encode target sequence\n",
    "def encode_output(sequences, vocab_size):\n",
    "    ylist = list()\n",
    "    for sequence in sequences:\n",
    "        encoded = to_categorical(sequence, num_classes=vocab_size)\n",
    "        ylist.append(encoded)\n",
    "    y = array(ylist)\n",
    "    y = y.reshape(sequences.shape[0], sequences.shape[1], vocab_size)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "id": "yXFq12OZIoYx"
   },
   "outputs": [],
   "source": [
    "trainX = encode_sequences(fre_tokenizer, fre_length, filt_clean_sen_l1[:1000])\n",
    "trainY = encode_sequences(eng_tokenizer, eng_length, filt_clean_sen_l2[:1000])\n",
    "trainY = encode_output(trainY, eng_vocab_size)\n",
    "# prepare validation data\n",
    "testX = encode_sequences(fre_tokenizer, fre_length, filt_clean_sen_l1[1000:1200])\n",
    "testY = encode_sequences(eng_tokenizer, eng_length, filt_clean_sen_l2[1000:1200])\n",
    "testY = encode_output(testY, eng_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tMtayD2XL76R"
   },
   "outputs": [],
   "source": [
    "testX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8PgX0q1uMkLd",
    "outputId": "9c3e6fd5-57f0-40cc-c1f2-c06c205b9907"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 20, 256)           2627584   \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 256)               525312    \n",
      "_________________________________________________________________\n",
      "repeat_vector_3 (RepeatVecto (None, 20, 256)           0         \n",
      "_________________________________________________________________\n",
      "lstm_7 (LSTM)                (None, 20, 256)           525312    \n",
      "_________________________________________________________________\n",
      "time_distributed_3 (TimeDist (None, 20, 8783)          2257231   \n",
      "=================================================================\n",
      "Total params: 5,935,439\n",
      "Trainable params: 5,935,439\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Create model\n",
    "def create_model(in_vocab, out_vocab, in_timesteps, out_timesteps, units):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(in_vocab, units, input_length=in_timesteps, mask_zero=True))\n",
    "    model.add(LSTM(units))\n",
    "    model.add(RepeatVector(out_timesteps))\n",
    "    model.add(LSTM(units, return_sequences=True))\n",
    "    model.add(TimeDistributed(Dense(out_vocab, activation='softmax')))\n",
    "    return model\n",
    "\n",
    "model = create_model(fre_vocab_size, eng_vocab_size, fre_length, eng_length, 256)\n",
    "\n",
    "#Compile Model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "id": "7D0vATFOU0T9"
   },
   "outputs": [],
   "source": [
    "# define model\n",
    "model = define_model(fre_vocab_size, eng_vocab_size, fre_length, eng_length, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "id": "nspnqBwZU4WW"
   },
   "outputs": [],
   "source": [
    "\n",
    "#RMS is good optimizer for RNNs\n",
    "rms = optimizers.RMSprop(lr=0.001)\n",
    "model.compile(optimizer=rms, loss='sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YjVCnonSVTLH"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy')\n",
    "# summarize defined model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hH6taZZlUiYM",
    "outputId": "72ac29e8-5bbf-4955-85b6-e24a1058f021"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 30, 256)           3963136   \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 256)               525312    \n",
      "_________________________________________________________________\n",
      "repeat_vector_4 (RepeatVecto (None, 30, 256)           0         \n",
      "_________________________________________________________________\n",
      "lstm_9 (LSTM)                (None, 30, 256)           525312    \n",
      "_________________________________________________________________\n",
      "time_distributed_4 (TimeDist (None, 30, 13308)         3420156   \n",
      "=================================================================\n",
      "Total params: 8,433,916\n",
      "Trainable params: 8,433,916\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())\n",
    "#plot_model(model, to_file='model.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "flwbrXwCNihB",
    "outputId": "49d6bd35-6b55-4bca-8336-b78b629dc245"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "7/7 [==============================] - 21s 3s/step - loss: 1.2807 - val_loss: 1.5146\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.51464, saving model to model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_8_layer_call_and_return_conditional_losses, lstm_cell_8_layer_call_fn, lstm_cell_9_layer_call_and_return_conditional_losses, lstm_cell_9_layer_call_fn, lstm_cell_8_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_8_layer_call_and_return_conditional_losses, lstm_cell_8_layer_call_fn, lstm_cell_9_layer_call_and_return_conditional_losses, lstm_cell_9_layer_call_fn, lstm_cell_8_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5\n",
      "7/7 [==============================] - 20s 3s/step - loss: 1.2680 - val_loss: 1.4944\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.51464 to 1.49443, saving model to model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_8_layer_call_and_return_conditional_losses, lstm_cell_8_layer_call_fn, lstm_cell_9_layer_call_and_return_conditional_losses, lstm_cell_9_layer_call_fn, lstm_cell_8_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_8_layer_call_and_return_conditional_losses, lstm_cell_8_layer_call_fn, lstm_cell_9_layer_call_and_return_conditional_losses, lstm_cell_9_layer_call_fn, lstm_cell_8_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5\n",
      "7/7 [==============================] - 20s 3s/step - loss: 1.2459 - val_loss: 1.5002\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.49443\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 20s 3s/step - loss: 1.2426 - val_loss: 1.4962\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.49443\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 20s 3s/step - loss: 1.2342 - val_loss: 1.4892\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.49443 to 1.48915, saving model to model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_8_layer_call_and_return_conditional_losses, lstm_cell_8_layer_call_fn, lstm_cell_9_layer_call_and_return_conditional_losses, lstm_cell_9_layer_call_fn, lstm_cell_8_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_8_layer_call_and_return_conditional_losses, lstm_cell_8_layer_call_fn, lstm_cell_9_layer_call_and_return_conditional_losses, lstm_cell_9_layer_call_fn, lstm_cell_8_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model/assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fd06be75850>"
      ]
     },
     "execution_count": 167,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit model\n",
    "filename = 'model'\n",
    "checkpoint = ModelCheckpoint(filename, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
    "\n",
    "model.fit(trainX, trainY, epochs=5, batch_size=128, validation_split = 0.2, callbacks=[checkpoint], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "TyH4JJZM6cT9"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-d4160b2fce18>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "preds = model.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yQey_A8EJAu-",
    "outputId": "c1fcae70-4c0f-4fa8-d76d-0b9682ddaf16"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 1s 206ms/step\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict_classes(testX,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SOeR5qWbPT0f",
    "outputId": "c3732fea-4ec3-49b6-aeb3-0d266405f543"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 171,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QiY-yVgCH7LJ",
    "outputId": "0b888dc7-eb47-4189-999d-aff72de0ee5f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1094,    1,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0], dtype=int32)"
      ]
     },
     "execution_count": 126,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testX[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "id": "8IZBNfnk6sHn"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hV69NiNDIBP5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "id": "SqWyYUEAIBaE"
   },
   "outputs": [],
   "source": [
    "#function to return array to words\n",
    "def get_word(n, tokenizer):\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index == n:\n",
    "            return word\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "id": "cX0LwlZoIBiJ",
    "outputId": "02e41a78-bd33-4ba4-e003-8932e9ba3900"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-123-59487b3221ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_word\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meng_tokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mj\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mget_word\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meng_tokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-122-b97befc7eb7f>\u001b[0m in \u001b[0;36mget_word\u001b[0;34m(n, tokenizer)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_word\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "#init predictions\n",
    "preds_text = []\n",
    "\n",
    "for i in preds:\n",
    "    temp = []\n",
    "    for j in range(len(i)):\n",
    "        t = get_word(i[j], eng_tokenizer)\n",
    "        if j > 0:\n",
    "            if (t == get_word(i[j-1], eng_tokenizer)) or (t == None): \n",
    "                temp.append('')\n",
    "            else:\n",
    "                temp.append(t)\n",
    "        else:\n",
    "            if(t == None):\n",
    "                temp.append('')\n",
    "            else:\n",
    "                temp.append(t) \n",
    "\n",
    "    preds_text.append(' '.join(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2xf1R3QMIFmn",
    "outputId": "3086323c-c05d-4777-f11c-2fff3d768943"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I',\n",
       " 'think',\n",
       " 'this',\n",
       " 'is',\n",
       " 'a',\n",
       " 'better',\n",
       " 'solution',\n",
       " 'than',\n",
       " 'proceeding',\n",
       " 'now',\n",
       " 'to',\n",
       " 'extremely',\n",
       " 'time-consuming',\n",
       " 'explanations',\n",
       " 'of',\n",
       " 'votes',\n",
       " '.']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "6EtuCLj2IFp3",
    "outputId": "b40b01fd-e5b9-4453-bbbc-131317281eba"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'                   '"
      ]
     },
     "execution_count": 89,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_text[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hRn0LzphIFse"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "ucA3qAwWOqQN"
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model, tokenizer, sources, raw_dataset):\n",
    "\tactual, predicted = list(), list()\n",
    "\tfor i, source in enumerate(sources):\n",
    "\t\t# translate encoded source text\n",
    "\t\tsource = source.reshape((1, source.shape[0]))\n",
    "\t\ttranslation = predict_sequence(model, eng_tokenizer, source)\n",
    "\t\traw_target = raw_dataset[i]\n",
    "\t\tactual.append([raw_target.split()])\n",
    "\t\tpredicted.append(translation.split())\n",
    "\t# calculate BLEU score\n",
    "\tprint('BLEU-1: %f' % corpus_bleu(actual, predicted, weights=(1.0, 0, 0, 0)))\n",
    "\tprint('BLEU-2: %f' % corpus_bleu(actual, predicted, weights=(0.5, 0.5, 0, 0)))\n",
    "\tprint('BLEU-3: %f' % corpus_bleu(actual, predicted, weights=(0.3, 0.3, 0.3, 0)))\n",
    "\tprint('BLEU-4: %f' % corpus_bleu(actual, predicted, weights=(0.25, 0.25, 0.25, 0.25)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "qo6iutGbQnzV",
    "outputId": "28ef7507-5116-4cd7-e186-6de9c778c4bf"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-53ec3f917f53>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meng_tokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-32-f47d2892e56a>\u001b[0m in \u001b[0;36mevaluate_model\u001b[0;34m(model, tokenizer, sources, raw_dataset)\u001b[0m\n\u001b[1;32m      6\u001b[0m                 \u001b[0mtranslation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meng_tokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                 \u001b[0mraw_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mraw_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m                 \u001b[0mactual\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mraw_target\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m                 \u001b[0mpredicted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranslation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;31m# calculate BLEU score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "evaluate_model(model, eng_tokenizer, testX, dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "mvGjKNJx5PuV"
   },
   "outputs": [],
   "source": [
    "def word_for_id(integer, tokenizer):\n",
    "\tfor word, index in tokenizer.word_index.items():\n",
    "\t\tif index == integer:\n",
    "\t\t\treturn word\n",
    "\treturn None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "oah4pP9y-UCA",
    "outputId": "7527c845-c985-4d17-de1f-30cf5544d75c"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'is'"
      ]
     },
     "execution_count": 42,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_for_id(5, eng_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "Y7_YasdV5JCp"
   },
   "outputs": [],
   "source": [
    "from numpy import argmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "ZNpbI87w43LS"
   },
   "outputs": [],
   "source": [
    "# generate target given source sequence\n",
    "def predict_sequence(model, tokenizer, source):\n",
    "\tprediction = model.predict(source, verbose=0)[0]\n",
    "\tintegers = [argmax(vector) for vector in prediction]\n",
    "\ttarget = list()\n",
    "\tfor i in integers:\n",
    "\t\tword = word_for_id(i, tokenizer)\n",
    "\t\tif word is None:\n",
    "\t\t\tbreak\n",
    "\t\ttarget.append(word)\n",
    "\treturn ' '.join(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "lMs7nRVPQz6J",
    "outputId": "3140d044-0e3a-4f96-835b-6715e84cfd3e"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'evaluate_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-a1c2184c208a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meng_tokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilt_clean_sen_l2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'evaluate_model' is not defined"
     ]
    }
   ],
   "source": [
    "evaluate_model(model, eng_tokenizer, X, filt_clean_sen_l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 163
    },
    "id": "ee58OFuOQ5nU",
    "outputId": "003f1283-20c1-46ba-fb18-d9cbbedba397"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-4dd69cb509d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredict_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meng_tokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilt_clean_sen_l1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'predict_sequence' is not defined"
     ]
    }
   ],
   "source": [
    "predict_sequence(model, eng_tokenizer, filt_clean_sen_l1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ShK1hMbZS7vN"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "mini_project_V.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
